# =============================================================================
# Semantic Search Backend - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in the required values.
# Required fields are marked with [REQUIRED], optional with [OPTIONAL]
# =============================================================================

# -----------------------------------------------------------------------------
# DEBUG MODE
# -----------------------------------------------------------------------------
# Set to true to enable DEBUG level logging (verbose output)
# Set to false (default) for INFO level logging in production
DEBUG=false

# -----------------------------------------------------------------------------
# API CONFIGURATION
# -----------------------------------------------------------------------------
API_HOST=0.0.0.0
API_PORT=8080
API_PREFIX=/api/v1

# -----------------------------------------------------------------------------
# DATABASE - PostgreSQL [REQUIRED]
# -----------------------------------------------------------------------------
POSTGRES_HOST=127.0.0.1
POSTGRES_PORT=5432
POSTGRES_DB=semantic_search
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

# -----------------------------------------------------------------------------
# VECTOR STORE - ChromaDB [REQUIRED]
# -----------------------------------------------------------------------------
CHROMA_HOST=localhost
CHROMA_PORT=8000

# =============================================================================
# LLM & EMBEDDING PROVIDERS
# =============================================================================
# The system supports multiple providers. Configure the ones you want to use.
# Model format: "provider:model_name" or just "model_name" for OpenAI (default)
#
# Examples:
#   EMBEDDING_MODEL=text-embedding-3-large          # OpenAI (default)
#   EMBEDDING_MODEL=ollama:nomic-embed-text-v2-moe:latest # Ollama (local, latest MoE)
#   EMBEDDING_MODEL=ollama:nomic-embed-text         # Ollama (local)
#   EMBEDDING_MODEL=jina:jina-embeddings-v2-base-en # Jina AI
#   EMBEDDING_MODEL=cohere:embed-english-v3.0       # Cohere
#   EMBEDDING_MODEL=voyage:voyage-large-2           # Voyage AI
# =============================================================================

# -----------------------------------------------------------------------------
# OPENAI [REQUIRED for default configuration]
# -----------------------------------------------------------------------------
# Required for: Embeddings (default), LLM (RAG answers), Answer Verification
# Get your key at: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# =============================================================================
# NOTE: The following settings are NOW MANAGED via the UI Settings page:
# - Embedding model, Chunk size, Chunk overlap
# - LLM model for answers and evaluations
# - Reranker provider, Search defaults
#
# They are NOT read from .env anymore. Configure them in the app at /settings
# =============================================================================

# Default models are set in DB Settings, not here
# EMBEDDING_MODEL=text-embedding-3-large  # Now in Settings page
# LLM_MODEL=gpt-4o-mini                   # Now in Settings page

# Available OpenAI Embedding Models:
# | Model                    | Dimensions | Notes              |
# |--------------------------|------------|--------------------|
# | text-embedding-3-large   | 3072       | Best quality       |
# | text-embedding-3-small   | 1536       | Fast & cheap       |
# | text-embedding-ada-002   | 1536       | Legacy             |

# Available OpenAI LLM Models:
# | Model         | Notes                              |
# |---------------|------------------------------------|
# | gpt-4o-mini   | Fast, cheap, good for RAG (default)|
# | gpt-4o        | Best quality, more expensive       |
# | gpt-4-turbo   | Good balance                       |
# | gpt-3.5-turbo | Fastest, cheapest                  |

# -----------------------------------------------------------------------------
# ANTHROPIC [OPTIONAL]
# -----------------------------------------------------------------------------
# Used for: LLM-as-Judge evaluations (RAG quality assessment)
# Get your key at: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=

# Available Anthropic Models for Evaluation:
# | Model                      | Notes                         |
# |----------------------------|-------------------------------|
# | claude-sonnet-4-20250514   | Fast, good quality (default)  |
# | claude-opus-4-20250514     | Best quality, more expensive  |

# -----------------------------------------------------------------------------
# OLLAMA [OPTIONAL - LOCAL, NO API KEY NEEDED]
# -----------------------------------------------------------------------------
# Runs locally on your machine. Great for Mac M4 with 24GB RAM.
# NO API KEY REQUIRED - completely free!
#
# Installation:
#   brew install ollama                    # macOS
#   ollama pull nomic-embed-text           # Download embedding model
#
# To use: EMBEDDING_MODEL=ollama:nomic-embed-text-v2-moe:latest
# To use: EMBEDDING_MODEL=ollama:nomic-embed-text
OLLAMA_BASE_URL=http://localhost:11434

# Available Ollama Embedding Models (pull before use):
# | Model                   | Dimensions | Notes                |
# |-------------------------|------------|----------------------|
# | nomic-embed-text        | 768        | Fast, good quality   |
# | mxbai-embed-large       | 1024       | High quality         |
# | all-minilm              | 384        | Lightweight          |
# | snowflake-arctic-embed  | 1024       | Strong retrieval     |

# -----------------------------------------------------------------------------
# JINA AI [OPTIONAL]
# -----------------------------------------------------------------------------
# Free tier: 1M tokens/month
# Get your key at: https://jina.ai/embeddings/
#
# To use embeddings: EMBEDDING_MODEL=jina:jina-embeddings-v2-base-en
JINA_API_KEY=

# Available Jina Embedding Models:
# | Model                        | Dimensions | Notes              |
# |------------------------------|------------|--------------------|
# | jina-embeddings-v2-base-en   | 768        | English, open src  |
# | jina-embeddings-v2-small-en  | 512        | Lightweight        |
# | jina-embeddings-v3           | 1024       | Latest, multilang  |

# -----------------------------------------------------------------------------
# COHERE [OPTIONAL]
# -----------------------------------------------------------------------------
# Used for: Embeddings (optional), Reranking (optional)
# Get your key at: https://cohere.com/
#
# To use embeddings: EMBEDDING_MODEL=cohere:embed-english-v3.0
COHERE_API_KEY=

# Available Cohere Embedding Models:
# | Model                     | Dimensions | Notes              |
# |---------------------------|------------|--------------------|
# | embed-english-v3.0        | 1024       | English optimized  |
# | embed-multilingual-v3.0   | 1024       | 100+ languages     |
# | embed-english-light-v3.0  | 384        | Fast English       |

# Available Cohere Reranker Models:
# | Model                     | Notes                    |
# |---------------------------|--------------------------|
# | rerank-english-v3.0       | English (default)        |
# | rerank-multilingual-v3.0  | 100+ languages           |

# -----------------------------------------------------------------------------
# VOYAGE AI [OPTIONAL]
# -----------------------------------------------------------------------------
# Optimized for RAG applications
# Get your key at: https://www.voyageai.com/
#
# To use: EMBEDDING_MODEL=voyage:voyage-large-2
VOYAGE_API_KEY=

# Available Voyage Embedding Models:
# | Model                    | Dimensions | Notes              |
# |--------------------------|------------|--------------------|
# | voyage-large-2           | 1536       | Best for RAG       |
# | voyage-code-2            | 1536       | Code optimized     |
# | voyage-2                 | 1024       | General purpose    |
# | voyage-lite-02-instruct  | 1024       | Lightweight        |

# =============================================================================
# RERANKER CONFIGURATION (NOW IN SETTINGS PAGE)
# =============================================================================
# Rerankers improve search quality by re-scoring results with cross-encoders.
# Priority: Jina (local, free) -> Cohere (cloud, requires API key)
#
# NOTE: Reranker selection is now configured in the Settings page, NOT here.
# =============================================================================

# Reranker provider is now in DB Settings
# RERANKER_PROVIDER=auto  # Now in Settings page
# USE_RERANKING=true      # Now in Settings page

# Available Jina Reranker Models (LOCAL, NO API KEY):
# | Model                                    | Notes                    |
# |------------------------------------------|--------------------------|
# | jinaai/jina-reranker-v1-tiny-en          | Fastest, English         |
# | jinaai/jina-reranker-v1-turbo-en         | Balanced                 |
# | jinaai/jina-reranker-v2-base-multilingual| Multilingual             |
#
# Installation: pip install sentence-transformers
# Model downloads automatically on first use (~100MB-500MB)

# =============================================================================
# RETRIEVAL SETTINGS (NOW IN SETTINGS PAGE)
# =============================================================================
# NOTE: These settings are now configured in the Settings page, NOT here.
#
# DEFAULT_SEARCH_K=5            # Now in Settings page
# DEFAULT_HYBRID_ALPHA=0.5      # Now in Settings page
# DEFAULT_RETRIEVAL_METHOD=hybrid  # Now in Settings page

# Hybrid search alpha explanation (for reference):
# | Alpha | Behavior                                    |
# |-------|---------------------------------------------|
# | 1.0   | Pure semantic search                        |
# | 0.7   | Mostly semantic, some keyword (high prec)   |
# | 0.5   | Balanced hybrid (default)                   |
# | 0.3   | Mostly keyword, some semantic (high recall) |
# | 0.0   | Pure BM25 keyword search                    |

# =============================================================================
# DOCUMENT PROCESSING (NOW IN SETTINGS PAGE)
# =============================================================================
# NOTE: Chunk settings are now configured in the Settings page, NOT here.
#
# CHUNK_SIZE=1000       # Now in Settings page
# CHUNK_OVERLAP=200     # Now in Settings page

# =============================================================================
# QUICK START GUIDE
# =============================================================================
#
# MINIMUM SETUP (OpenAI only):
# 1. Set OPENAI_API_KEY
# 2. Start PostgreSQL and ChromaDB (docker-compose up -d)
# 3. Run: uvicorn app.main:app --reload --port 8080
#
# FREE LOCAL SETUP (Ollama + Jina Reranker):
# 1. Install Ollama: brew install ollama
# 2. Pull model: ollama pull nomic-embed-text
# 3. Set EMBEDDING_MODEL=ollama:nomic-embed-text-v2-moe:latest
# 4. Install sentence-transformers: pip install sentence-transformers
# 5. Set RERANKER_PROVIDER=jina
# Note: Still needs OPENAI_API_KEY for RAG answer generation
#
# =============================================================================
